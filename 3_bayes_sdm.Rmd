---
title: "Logistic Regression Example"
author: "Martin Ingram"
date: "05/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# The problem

To introduce a more realistic modelling scenario, we're going to have a species distribution modelling example. Note that even if you're not interested in modelling species distributions, the logistic regression model we'll use has wide applicability. 

We have what's called "survey data": people went out into the field and checked whether a certain bird was present or absent at a site. These are our outcomes $y_{ij}$: at site $i$, species $j$ was either observed ($y_{ij} = 1$) or not observed ($y_{ij} = 0$). We also have access to a number of covariates, a subset of the so-called "BIOCLIM" variables:

```
BIO1 = Annual Mean Temperature
BIO2 = Mean Diurnal Range (Mean of monthly (max temp - min temp))
BIO3 = Isothermality (BIO2/BIO7) (* 100)
BIO4 = Temperature Seasonality (standard deviation *100)
BIO5 = Max Temperature of Warmest Month
BIO6 = Min Temperature of Coldest Month
BIO7 = Temperature Annual Range (BIO5-BIO6)
BIO8 = Mean Temperature of Wettest Quarter
BIO9 = Mean Temperature of Driest Quarter
BIO10 = Mean Temperature of Warmest Quarter
BIO11 = Mean Temperature of Coldest Quarter
BIO12 = Annual Precipitation
BIO13 = Precipitation of Wettest Month
BIO14 = Precipitation of Driest Month
BIO15 = Precipitation Seasonality (Coefficient of Variation)
BIO16 = Precipitation of Wettest Quarter
BIO17 = Precipitation of Driest Quarter
BIO18 = Precipitation of Warmest Quarter
BIO19 = Precipitation of Coldest Quarter
```

What we are interested in is the influence of these covariates on whether or not a species is present or absent at a site. If we can model this well, we can perhaps hope to predict new sites well that are similar.

The data we're going to used is from the "Breeding Bird Survey", which contains presence or absence for 371 different bird species in the USA. We also have access to 8 different environmental covariates.

## Modelling

First, we're going to load in our data:

```{r}
x <- read.csv('./x_train.csv', row.names=1)
y <- read.csv('./y_train.csv', row.names=1, check.names=FALSE)
```

Let's take a look at the data:

```{r}
head(x)
```

We have 8 different biological variables. What about the outcomes?

```{r}
head(y)[, 1:8]
```

We have 371 different birds which are present if the entry in the row is 1 and absent otherwise.

Let's pick one bird to model: the Wood Duck.

```{r}
y_wood <- y[, 'Wood Duck']
head(y_wood)
```

Great! We have the vector of presence / absence data.

One thing that is usually good to do before a regression is to centre and scale our data. Right now, we see that the covariates have large integer values, and their mean and standard deviations are not 0 and 1:

```{r}
head(x)

print('Means:')
colMeans(x)

print('Standard deviations:')
apply(x, 2, sd)
```

Let's fix that with R's scale function:

```{r}
x_scaled <- scale(x)

head(x_scaled)
print('Means:')
colMeans(x_scaled)

print('Standard deviations:')
apply(x_scaled, 2, sd)
```

Great! Now we've standardised our data, let's think about how we're going to model our data. We'll have to specify two things: our _prior_, and our _likelihood_.

The likelihood is quite straightforward here. We have a binary outcome, so the natural likelihood to use is the Bernoulli likelihood. We can write this as:

$$
y_i \sim \textrm{Bern}(p_i)
$$

This notation means that the $y_i$, the presence ($y_i = 1$) or absence ($y_i = 0$) of the species at site $i$ is distributed as a Bernoulli distribution with success probability $p_i$. Note that this is exactly the same as our coin toss example from earlier!

That's all very well, but how do we model the probability of presence, $p_i$? There are lots of options, but here we're just going to go with a linear model. To start with, we also just use one covariate plus an intercept (we'll move to more later). We could imagine doing

$$
p_i = \theta_1 x_i + \theta_2
$$

But this has a big problem: we could get predicted probabilities greater than 1, or smaller than zero. Just imagine, for example, that $x$ is temperature (standardised). Now let's assume that the relationship between temperature and presence or absence is strong. We could for example have $\theta_1=0.75$ and set $\theta_2$, the intercept, to zero. Then our prediction for $p_i$ would be:

```{r}
x_plot <- seq(-2, 2, length.out = 100)
theta_1 <- 0.75
p_i <- theta_1 * x_plot

plot(x_plot, p_i)
```

Note how we would be predicting negative probabilities, and also some that are greater than 1! That doesn't work.
NOTE: In some cases, you can get away with doing this, if you use a Gaussian likelihood. But we won't go into that here.

Instead, we use something called the inverse logit "link function" to turn our linear prediction into a valid probability:

$$
p_i = \textrm{logit}^{-1}(\theta_1 x + \theta_2)
$$

This function is called `plogis` in R. Let's look at what our example would look like:

```{r}
x_plot <- seq(-2, 2, length.out = 100)
theta_1 <- 0.75
p_i <- plogis(theta_1 * x_plot)

plot(x_plot, p_i)
```

See what happened? The inverse logit function "squashes" the function values between 0 and 1, making them valid probabilities.

What priors should we give our linear model parameters? Here, it's not completely crucial, since we have a lot of data and only two parameters, so the data will "overwhelm" any prior we might use. Still, let's work out something reasonable.

We can do something called "prior predictive checks" to work out if our priors make any sense. The way we do this is we generate fake data from our prior and see whether it looks reasonable. For example of what may not be reasonable, let's say we do:

$$
\theta_1 \sim \mathcal{N}(0, 100^2) \\
\theta_2 \sim \mathcal{N}(0, 100^2) \\
y_i \sim \textrm{Bern}(\textrm{logit}^{-1}(\theta_1 x_i + \theta_2))
$$

We can simulate from this prior using R's built-in functions. Let's see what happens:

```{r}
n_samples <- 1
prior_sd <- 100

# We'll just use the first variable to fit
# This is "BIO2", which is the "mean diurnal range" (Mean of monthly (max temp - min temp))
x_fit <- x_scaled[, 1]

# Draw samples from the priors
theta_1 <- rnorm(n_samples, mean = 0, sd = prior_sd)
theta_2 <- rnorm(n_samples, mean = 0, sd = prior_sd)

# Calculate our p_i:
p_i <- plogis(theta_1 * x_fit + theta_2)

hist(p_i, breaks=50)
```

We see that under this prior, the model is almost perfectly certain the bird is present at some point, and almost perfectly certain it isn't present at others. That doesn't seem reasonable; it's much more likely that the bird is more likely to be at some sites than others, but hardly that we can say with almost 100% confidence that it will be present or absent.

These so-called "non-informative" priors used to be popular because they try to minimise the influence of the prior distribution. Many people advocate for ditching these priors these days however and instead using priors that we can justify. For simple models, it doesn't really matter, but for more complicated models it's important that you think about your priors and choose ones that produce reasonable data.

Let's try a more reasonable setup:
$$
\theta_1 \sim \mathcal{N}(0, 1^2) \\
\theta_2 \sim \mathcal{N}(0, 1^2) \\
y_i \sim \textrm{Bern}(\textrm{logit}^{-1}(\theta_1 x_i + \theta_2))
$$
Let's simulate from the prior again:

```{r}
n_samples <- 1
prior_sd <- 1

# We'll just use the first variable to fit
x_fit <- x_scaled[, 1]

# Draw samples from the priors
theta_1 <- rnorm(n_samples, mean = 0, sd = prior_sd)
theta_2 <- rnorm(n_samples, mean = 0, sd = prior_sd)

# Calculate our p_i:
p_i <- plogis(theta_1 * x_fit + theta_2)

hist(p_i, breaks=50)
```

I hope you agree that that looks much more reasonable! We now have some sites where we have high confidence and others where we are less certain.

Now that we have a reasonable prior, let's write this model up in Stan:

```
data {
  int n_obs; // Number of observations
  int y[n_obs]; // Presence / absence at each site
  vector[n_obs] x; // Covariate
}
parameters {
  real theta_1; // Slope
  real theta_2; // Intercept
}
model {
  // Priors
  theta_1 ~ normal(0, 1);
  theta_2 ~ normal(0, 1);
  
  y ~ bernoulli_logit(theta_1 * x + theta_2);
}
```

There's a few new things here. Let's make sure we understand them.

* Our `y` is now what is called an `array`, because we have `n_obs` observations, one for each site. Note the placement of the square brackets _after_ the variable. It is still integer, because it can only be 0 and 1.
* Our predictors `x` are a `vector[n_obs]`. Note that here, the square brackets are before the the variable name. This is admittedly a bit confusing, but that's the way it works.
* Note that we wrote `y ~ bernoulli_logit(...)`. Because it's so common to use the inverse logit transformation, $\textrm{logit}^{-1}$, together with the Bernoulli likelihood, Stan gives us a function to do it in one go. We could also have done: `y ~ bernoulli(inv_logit(...))`, but this way is better.
* Finally, note that Stan has "vectorised" this. Even though `y` is an array, we don't have to write a loop (although we could have). This way is usually faster and easier to read.

If you have any questions, please let me know, we can talk about this at length.

Now, let's load this Stan model (as usual, we saved it to a file):

```{r}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores=parallel::detectCores())
model <- stan_model('./log_reg_model.stan')
```

We need to put together our data for Stan:

```{r}
model_data <- list(
  n_obs = length(x_fit),
  y = y_wood,
  x = x_fit
)
```

Now we can sample from this model using Stan's MCMC sampler:

```{r}
draws <- sampling(model, model_data)
```

OK, great! Now let's look at the summary Stan provides us with:

```{r}
print(draws)
```

Good: the `Rhat` statistic is 1, and we have a high number of effective samples, which indicate that the chains have likely converged.

Stan also provides a plot function:

```{r}
plot(draws)
```

So it looks like the slope $\theta_1$ is slightly negative, and the intercept $\theta_2$ is quite small, at around -2.

We can also just look at some histograms:

```{r}
theta_1 <- extract(draws, 'theta_1')$theta_1

hist(theta_1)
```

```{r}
theta_2 <- extract(draws, 'theta_2')$theta_2

hist(theta_2)
```

And we can answer some questions, like: how likely is it that the slope is smaller than -0.2?

```{r}
mean(theta_1 < -0.2)
```

We can also plot the response with error bars.

```{r}
x_plot <- seq(-2, 2, length.out = 100)
# The sapply here just means that for each x value, we're going to calculate:
# The mean of the posterior draws
# The 2.5% and 97.5% quantiles
y_mean <- sapply(x_plot, function(x) mean(plogis(theta_1 * x + theta_2)))
y_lower <- sapply(x_plot, function(x) quantile(plogis(theta_1 * x + theta_2), 0.025))
y_upper <- sapply(x_plot, function(x) quantile(plogis(theta_1 * x + theta_2), 0.975))
```

```{r}
library(ggplot2)

data <- data.frame(x_plot, y_mean, y_lower, y_upper)

p <- ggplot(data = data, mapping = aes(x=x_plot, y=y_mean, ymin=y_lower, ymax=y_upper)) +
  geom_line() +
  geom_ribbon(alpha=0.5) +
  theme_classic() +
  xlab('Diurnal Range (standardised)') +
  ylab('Probability of presence')

p
```

We see that it looks like the Wood Duck seems to be more likely to be present in climates with small diurnal range.

## Exercises

1. Fit the same model to another bird species, the "American Wigeon". The easiest way is to just change the species name at the right secion in the file. What's the probability that its slope $\theta_1$ is greater than 0?
2. Add a second covariate to the model, `bio3` ("isothermality"), and fit the Wood Duck again. You'll have to make a copy of the Stan file and modify that; and then feel free to add the new code to fit it to the bottom of this file. What are the 95% credible intervals for the slopes on the two covariates?
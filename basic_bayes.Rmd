---
title: "Basic Bayes"
author: "Martin Ingram"
date: "05/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intro to Bayes' rule

Let's start off with something we'll call:

$$
p(\theta)
$$

This is the so-called _prior_ probability: our belief about $\theta$ before we have any data. For example, if someone asks you what the probability is that it'll rain tomorrow, you can probably make up some number.

Bayes' rule is all about going from _prior_ to _posterior_ probability. We have a prior $p(\theta)$, as we just described; then we observe some data, $y$. We want to know how we should update our belief about $\theta$. For example, if you now see that the weather forecast for tomorrow says it'll probably rain, you might want to update your belief (but perhaps you don't fully trust the weather forecast, so you don't just accept it completely).

What we want is the so-called _posterior distribution_:

$$
p(\theta | y)
$$

This is the value of $\theta$ _given_ our new data $y$. Bayes' rule tells us how to get from $p(\theta)$ to $p(\theta | y)$:

$$
p(\theta | y) = \frac{p(\theta) p(y | \theta)}{p(y)}
$$

There are two other terms in here we should get familiar with. Firstly:

$$
p(y | \theta)
$$

This is the _likelihood_ of the data we observe for a given parameter $\theta$. The likelihood is how data enters into the model and is what will make us revise our beliefs.

Finally, $p(y)$ normalises the product of the prior and the likelihood to sum to 1. Today, this term will mainly be a nuisance (we'll see why), but it can be useful for some purposes.

## An example of using Bayes' rule with probabilities

Bayes' rule can be used for probabilities, where it can sometimes lead to surprising results. For example, consider the following scenario.

```
You go to see the doctor. As part of a checkup, the doctor tests you for a rare disease, e.g. cancer. This particular disease affects 1 in 1000 people of your age. If you have the disease, the test will test positive with 99% probability. If you don't have the disease, the test will give a negative with 99% probability. You test positive. How worried should you be?
```

Let's translate this into the language of probabilities:

$$
p(D = 1) = \frac{1}{1000} \\
p(T = 1|D = 1) = 0.99 \\
p(T = 0|D = 0) = 0.99
$$

What we want is $p(D = 1 | T = 1)$. This is exactly the situation of Bayes' rule: we have a prior probability $p(D)$, we get new data (the positive test result, $T = 1$), and we want to find our new probability of having the disease. We know $p(T|D)$, the likelihood. So:

$$
p(D = 1|T = 1) = \frac{p(D = 1)p(T = 1|D = 1)}{p(T = 1)} = \frac{\frac{0.99}{1000}}{p(T = 1)}
$$

What's $p(T = 1)$? We're not going to go into probability theory here much, but what we can do is:

$$
p(T = 1) = p(T = 1, D = 0) + p(T = 1, D = 1) = \\
p(T = 1|D = 0)p(D = 0) + p(T = 1 | D = 1)p(D = 1) = \\
(1 - 0.99) (1 - \frac{1}{1000}) + 0.99 \frac{1}{1000}
$$
Let's calculate that:

```{r}
denominator <- (1 - 0.99) * (1 - (1 / 1000)) + 0.99 / 1000
numerator <- 0.99 / 1000

numerator / denominator
```

So our new probability is just over 9%. Not tiny, maybe big enough to get a little bit queasy, but it's still pretty unlikely that we have the disease. We could take another test to get more information, where our prior would now be $p(D = 1) \approx 0.09$.

## Bayesian coin tosses

Another simple Bayesian example involves repeated samples with the same success probability.

Let's say someone gives you a coin and you want to work out the probability it comes up heads. This example might be contrived (I don't usually test coins like that), but keep in mind that things in probability are often _isomorphic_: maybe you don't care about coins, but you're interested in someone's probability of scoring a penalty in soccer, or in how likely you are to see a particular animal when you repeatedly visit a site.

Anyway, the example: what we're interested in is $\theta$, the probability that the coin comes up heads when tossed. We'll say that this coin _could_ be biased: we don't know (otherwise it's just 50% and boring).

If we want to use Bayes' theorem here, we first need a prior. To keep things simple, we'll start off with a Uniform distribution:

```{r}
x <- seq(0, 1, length.out=100)
y <- rep(1, 100)

plot(x, y, ylim=c(0, 1), xlab=expression(theta), ylab=expression('p(' ~ theta ~ ')'), type='l')
```

Now, we need a likelihood. In this case, we'll use the Bernoulli likelihood. It looks like this:

$$
p(y = 1|\theta) = \theta \\
p(y = 0|\theta) = 1 - \theta
$$

I hope this makes sense: the likelihood of observing heads ($y = 0$) given the probability of heads $\theta$ is just $\theta$, and that for tails is its complement, $1 - \theta$.

So now we have our prior and likelihood. Let's say we toss the coin and it comes up heads. What's our new belief about $\theta$? Once again, we use Bayes' rule:

$$
p(\theta | y = 1) = \frac{p(\theta) p(y = 1 | \theta)}{p(y = 1)}
$$

Since we're using a uniform prior here, $p(\theta)$ is just 1. We can use Bayes rule again:

$$
p(\theta | y = 1) = \frac{\theta}{\int_{0}^1 p(y = 1 | \theta) p(\theta) d\theta} = \frac{\theta}{\int_{0}^1 \theta d\theta} = \frac{\theta}{0.5} = 2\theta
$$

So our posterior is now:

```{r}
theta_plot <- function(x, y, ylim=NULL) {
  plot(x, y, xlab=expression(theta), ylab=expression('p(' ~ theta ~ ')'), type='l', col='red', ylim=ylim)
}

x <- seq(0, 1, length.out=100)
yprior <- rep(1, 100)
ypost <- 2 * x

theta_plot(x, ypost)
lines(x, yprior, ylim=c(0, 2), col='green')
```

I'm guessing you don't like integrals. And this one was an easy one! We'd have to solve one every time we toss a new coin, and they get a bit more complicated. Luckily, this particular problem has a solution: it turns out that if our prior is a so-called Beta distribution:

$$
p(\theta) = \textrm{Beta}(\theta | \alpha, \beta) \\
\textrm{often also written as } \theta \sim \textrm{Beta}(\alpha, \beta)
$$

You'll see the second version often in the literature: $\theta$ _is distributed as_ $\textrm{Beta}(\alpha, \beta)$.

If this is the case, then:

$$
p(\theta | y = 1) \sim \textrm{Beta}(\alpha + 1, \beta)
$$
In other words, if we observe a success, we increment the first parameter of the Beta distribution. Let's see what this looks like:

```{r}
x <- seq(0, 1, length.out = 100)

# Uniform prior:
prior <- dbeta(x, 1, 1)

# Posterior after observing one head
post <- dbeta(x, 2, 1)

theta_plot(x, prior, ylim=c(0, 2))
lines(x, post, col='green')
```

The same as before!

OK, well, let's get more interesting. Suppose you toss the coin 10 times and it comes up heads 6 times. What's your posterior now? Turns out it's:

$$
p(\theta | y_1, y_2, ... y_{10}) = \textrm{Beta}(1 + 6, 1 + 4) = \textrm{Beta}(7, 5)
$$

```{r}
x <- seq(0, 1, length.out = 100)
n_heads <- 6
n_tails <- 4

# Posterior after observing one head
posterior <- dbeta(x, n_heads + 1, n_tails + 1)

theta_plot(x, posterior)
```

How cool is that! We can now answer some questions about this. If we had to guess a mean success probability, what would that be? We can do maths, but let's simulate instead (we'll do that from now on). We'll draw from this distribution a few thousand times and compute what we're interested in. This is called a "Monte Carlo" estimate.

```{r}
n_draws <- 10000
samples <- rbeta(n_draws, 1 + n_heads, 1 + n_tails)

hist(samples)
```

The mean is:

```{r}
mean(samples)
```

And the probability that the success probability is greater than 60% is approximately:

```{r}
mean(samples > 0.6)
```

As we observe more and more tosses, the distribution gets narrower and narrower, reflecting us gaining more and more knowledge:

```{r}
x <- seq(0, 1, length.out = 1000)
n_heads <- 200
n_tails <- 210

# Posterior after observing one head
posterior <- dbeta(x, n_heads + 1, n_tails + 1)

theta_plot(x, posterior)
```

## Exercises

##### Exercise 1

(well-known) You play poker with the Archbishop of Canterbury. It turns out that he has a royal flush, which has a probability of only $1.54 \times 10^{-6}$. However, being a reputable man, you believe it is very unlikely that the Archbishop would cheat -- say 1 in a million, $1 \times 10^{-6}$. Use Bayes' rule to work out the probability that the Archbishop cheated.

##### Exercise 2

You play tennis against your friend 5 times. You win 4 times and lose once. Assuming you had no idea how likely you were to win initially, what is the posterior distribution of your win probability? What is the probability that your win probability is greater than 50%?
---
title: "Species distribution models"
author: "Martin Ingram"
date: "05/08/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, we're going to load in our data:

```{r}
x <- read.csv('./x_train.csv', row.names=1)
y <- read.csv('./y_train.csv', row.names=1, check.names=FALSE)
```

Let's take a look at the data:

```{r}
head(x)
```

We have 8 different biological variables. What about the outcomes?

```{r}
head(y)
```

We have 371 different birds which are present if the entry in the row is 1 and absent otherwise.

Let's pick one bird to model: the Wood Duck.

```{r}
y_wood <- y[, 'Wood Duck']
head(y_wood)
```

Great! We have the vector of presence / absence data.

One thing that is (almost) always good to do before a regression is to centre and scale our data. Right now, we see that the covariates have large integer values, and their mean and standard deviations are not 0 and 1:

```{r}
head(x)

print('Means:')
colMeans(x)

print('Standard deviations:')
apply(x, 2, sd)
```

Let's fix that with R's scale function:

```{r}
x_scaled <- scale(x)

head(x_scaled)
print('Means:')
colMeans(x_scaled)

print('Standard deviations:')
apply(x_scaled, 2, sd)
```

Great! Now we've standardised our data, let's think about how we're going to model our data. We'll have to specify two things: our _prior_, and our _likelihood_.

The likelihood is quite straightforward here. We have a binary outcome, so the natural likelihood to use is the Bernoulli likelihood. We can write this as:

$$
y_i \sim \textrm{Bern}(p_i)
$$

This notation means that the $y_i$, the presence ($y_i = 1$) or absence ($y_i = 0$) of the species at site $i$ is distributed as a Bernoulli distribution with success probability $p_i$.

That's all very well, but how do we model the probability of presence, $p_i$? There are lots of options, but here we're just going to go with a linear model. To start with, we also just use one covariate plus an intercept. We could imagine doing

$$
p_i = \theta_1 x_i + \theta_2
$$

But this has a big problem: we could get predicted probabilities greater than 1, or smaller than zero. Just imagine, for example, that $x$ is temperature (standardised). Now let's assume that the relationship between temperature and presence or absence is strong. We could for example have $\theta_1=0.75$ and set $\theta_2$, the intercept, to zero. Then our prediction for $p_i$ would be:

```{r}
x_plot <- seq(-2, 2, length.out = 100)
theta_1 <- 0.75
p_i <- theta_1 * x_plot

plot(x_plot, p_i)
```

Note how we would be predicting negative probabilities, and also some that are greater than 1! That doesn't work.
NOTE: In some cases, you can get away with doing this, if you use a normal likelihood. But we won't go into that here.

Instead, we use something called the inverse logit "link function" to turn our linear prediction into a valid probability:

$$
p_i = \textrm{logit}^{-1}(\theta_1 x + \theta_2)
$$

This function is called `plogis` in R. Let's look at what our example would look like:

```{r}
x_plot <- seq(-2, 2, length.out = 100)
theta_1 <- 0.75
p_i <- plogis(theta_1 * x_plot)

plot(x_plot, p_i)
```

See what happened? The inverse logit function "squashes" the function values between 0 and 1, making them valid probabilities.

What priors should we give our linear model parameters? Here, it's not completely crucial, since we have a lot of data and only two parameters, so the data will "overwhelm" any prior we might use. Still, let's work out something reasonable.

We can do something called "prior predictive checks" to work out if our priors make any sense. The way we do this is we generate fake data from our prior and see whether it looks reasonable. For example of what may not be reasonable, let's say we do:

$$
\theta_1 \sim \mathcal{N}(0, 100^2) \\
\theta_2 \sim \mathcal{N}(0, 100^2) \\

y_i \sim \textrm{Bern}(\textrm{logit}^{-1}(\theta_1 x_i + \theta_2))
$$

We can simulate from this prior using R's built-in functions. Let's see what happens:

```{r}
n_samples <- 1
prior_sd <- 100

# We'll just use the first variable to fit
# This is "BIO2", which is the "mean diurnal range" (Mean of monthly (max temp - min temp))
x_fit <- x_scaled[, 1]

# Draw samples from the priors
theta_1 <- rnorm(n_samples, mean = 0, sd = prior_sd)
theta_2 <- rnorm(n_samples, mean = 0, sd = prior_sd)

# Calculate our p_i:
p_i <- plogis(theta_1 * x_fit + theta_2)

hist(p_i, breaks=50)
```

We see that under our prior, the model is almost perfectly certain the bird is present at some point, and almost perfectly certain it isn't present at others. That doesn't seem reasonable; it's much more likely that the bird is more likely to be at some sites than others, but hardly that we can say with almost 100% confidence that it will be present or absent.

These so-called "non-informative" priors used to be popular because they try to minimise the influence of the prior distribution. Many people advocate for ditching these priors these days however and instead using priors that make sense. For simple models, it doesn't really matter, but for more complicated models it's important that you think about your priors and choose ones that produce reasonable data.

Let's try a more reasonable setup:
$$
\theta_1 \sim \mathcal{N}(0, 1^2) \\
\theta_2 \sim \mathcal{N}(0, 1^2) \\

y_i \sim \textrm{Bern}(\textrm{logit}^{-1}(\theta_1 x_i + \theta_2))
$$
Let's simulate from the prior again:

```{r}
n_samples <- 1
prior_sd <- 1

# We'll just use the first variable to fit
x_fit <- x_scaled[, 1]

# Draw samples from the priors
theta_1 <- rnorm(n_samples, mean = 0, sd = prior_sd)
theta_2 <- rnorm(n_samples, mean = 0, sd = prior_sd)

# Calculate our p_i:
p_i <- plogis(theta_1 * x_fit + theta_2)

hist(p_i, breaks=50)
```

I hope you agree that that looks much more reasonable! We now have some sites where we have high confidence and others where we are less certain.

Now that we have a reasonable prior, let's write this model up in Stan:

```{r}
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores=parallel::detectCores())
model <- stan_model('./log_reg_model.stan')
```

We need to put together our data for Stan:

```{r}
model_data <- list(
  n_obs = length(x_fit),
  y = y_wood,
  x = x_fit
)
```

Now we can sample from this model using Stan's MCMC sampler:

```{r}
draws <- sampling(model, model_data)
```

OK, great! Now let's look at the summary Stan provides us with:

```{r}
print(draws)
```

Good: the `Rhat` statistic is 1, and we have a high number of effective samples, which indicate that are chains have likely converged.

Stan also provides a plot function:

```{r}
plot(draws)
```

So it looks like the slope is slightly negative, and the intercept is quite small, at around -2.

We can also just look at some histograms:

```{r}
theta_1 <- extract(draws, 'theta_1')$theta_1

hist(theta_1)
```

```{r}
theta_2 <- extract(draws, 'theta_2')$theta_2

hist(theta_2)
```

And we can answer some questions, like: how likely is it that the slope is smaller than -0.2?

```{r}
mean(theta_1 < -0.2)
```

We can also plot the response with error bars.

```{r}
x_plot <- seq(-2, 2, length.out = 100)
y_mean <- sapply(x_plot, function(x) mean(plogis(theta_1 * x + theta_2)))
y_lower <- sapply(x_plot, function(x) quantile(plogis(theta_1 * x + theta_2), 0.025))
y_upper <- sapply(x_plot, function(x) quantile(plogis(theta_1 * x + theta_2), 0.975))
```

```{r}
library(ggplot2)

data <- data.frame(x_plot, y_mean, y_lower, y_upper)

p <- ggplot(data = data, mapping = aes(x=x_plot, y=y_mean, ymin=y_lower, ymax=y_upper)) +
  geom_line() +
  geom_ribbon(alpha=0.5) +
  theme_classic() +
  xlab('Diurnal Range (standardised)') +
  ylab('Probability of presence')

p
```

We see that it looks like the Wood Duck is happier in climates with small diurnal range.

## Exercises

Fit the same model to another bird species, the "American Wigeon". The easiest way is to just change the species name at the right secion in the file. What can you say about the posteriors for the slope and the intercept?